## 7.4-1

> Mostre que na recorrência
>
> $$
> \begin{aligned}
> T(n) & = \max\limits_{0 \le q \le n - 1} (T(q) + T(n - q - 1)) + \Theta(n), \\\\
> T(n) & = \Omega(n^2).
> \end{aligned}
> $$

Nós assumimos $T(n) \ge cn^2 - 2n$,

$$
\begin{aligned}
T(n) & =   \max_{0 \le q \le n - 1} (T(q) + T(n - q - 1)) + \Theta(n) \\\\
     & \ge \max_{0 \le q \le n - 1} (cq^2 - 2q + c(n - q - 1)^2 - 2n - 2q -1) + \Theta(n) \\\\
     & \ge c\max_{0 \le q \le n - 1} (q^2 + (n - q - 1)^2 - (2n + 4q + 1) / c) + \Theta(n) \\\\
     & \ge cn^2 - c(2n - 1) + \Theta(n) \\\\
     & \ge cn^2 - 2cn + 2c & (c \le 1) \\\\
     & \ge cn^2 - 2n.
\end{aligned}
$$

## 7.4-2

> Mostre que o tempo de execução do melhor caso do quicksort é $\Omega(n\lg n)$.

Usaremos o método de substituição para mostrar que o tempo de execução no melhor caso é $\Omega(n\lg n)$. Seja $T(n)$ o tempo de melhor caso para o procedimento $\text{QUICKSORT}$ em uma entrada de tamanho $n$. Temos

$$T(n) = \min _{1 \le q \le n - 1} (T(q) + T(n - q - 1)) + \Theta(n).$$

Suponha que $T(n) \ge c(n\lg n + 2n)$ para alguma constante $c$. Substituir essa suposição na recorrência dá

$$
\begin{aligned}
T(n) & \ge \min _{1 \le q \le n - 1}(cq\lg q + 2cq + c(n - q - 1) \lg(n - q - 1) + 2c(n - q - 1)) + \Theta(n) \\\\
     & =   (cn / 2)\lg(n / 2) + cn + c(n / 2 - 1)\lg(n / 2 - 1) + cn - 2c + \Theta(n) \\\\
     & \ge (cn / 2)\lg n - cn / 2 + c(n / 2 - 1)(\lg n - 2) + 2cn - 2c\Theta(n) \\\\
     & =   (cn / 2)\lg n - cn / 2 + (cn / 2) \lg n - cn - c\lg n + 2c + 2cn - 2c\Theta(n) \\\\
     & =   cn\lg n + cn / 2 - c\lg n + 2c - 2c\Theta(n).
\end{aligned}
$$

Derivando em relação a $q$ mostra que o mínimo é obtido quando $q = n / 2$. Escolher $c$ grande o suficiente para dominar o termo $−\lg n + 2 − 2c + \Theta(n)$ torna isso maior que $cn\lg n$, provando o limite inferior.

## 7.4-3

> Mostre que a expressão $q^2 + (n - q - 1)^2$ atinge o máximo para $q = 0$ e $q = n - 1$.

$$
\begin{aligned}
  f(q) & = q^2 + (n - q - 1)^2 \\\\
 f'(q) & = 2q - 2(n - q - 1) = 4q - 2n + 2 \\\\
f''(q) & = 4. \\\\
\end{aligned}
$$

$f'(q) = 0$ quando $q = \frac{1}{2}n - \frac{1}{2}$. $f'(q)$ também é contínuo. Para todo $q: f''(q) > 0$, o que significa que $f'(q)$ é negativo à esquerda de $f'(q) = 0$ e positivo à direita, o que significa que este é um mínimo local. Neste caso, $f(q)$ está decrescendo no início do intervalo e aumentando no final, o que significa que esses dois pontos são os únicos candidatos para um máximo no intervalo.

$$
\begin{aligned}
    f(0) & = (n - 1)^2 \\\\
f(n - 1) & = (n - 1)^2 + 0^2.
\end{aligned}
$$

## 7.4-4

> Mostre que o tempo de execução esperado do $\text{RANDOMIZED-QUICKSORT}$ é $\Omega(n\lg n)$.

Usamos o mesmo raciocínio para o número esperado de comparações, apenas seguimos em uma direção diferente.

$$
\begin{aligned}
\text E[X]
    & =   \sum_{i = 1}^{n - 1} \sum_{j = i + 1}^n \frac{2}{j - i + 1} \\\\
    & =   \sum_{i = 1}^{n - 1} \sum_{k = 1}^{n - i} \frac{2}{k + 1} & (k \ge 1) \\\\
    & \ge \sum_{i = 1}^{n - 1} \sum_{k = 1}^{n - i} \frac{2}{2k} \\\\
    & \ge \sum_{i = 1}^{n - 1} \Omega(\lg n) \\\\
    & =   \Omega(n\lg n).
\end{aligned}
$$

Usando o método mestre, obtemos a solução $\Theta(n\lg n)$.

## 7.4-5

> Simplificar a recursão, como fizemos no Problema 2-1 para o merge sort, é uma maneira comum de melhorar o tempo de execução do quicksort na prática. Modificamos o caso base da recursão para que, se o array tiver menos de k elementos, o subarray seja ordenado pelo insertion sort, em vez de chamadas recursivas contínuas para o quicksort. Argumente que a versão randomizada desse algoritmo de ordenação roda em tempo esperado $O(nk + n\lg(n / k))$. Como você deve escolher $k$, tanto na teoria quanto na prática?

Primeiro vamos mostrar que ao parar em nós com $k$ elementos, a altura da árvore é $O(\lg(n/k))$. Considere que a cada nível, a quantidade de elementos reduz de $n$ para $n/a$, sendo $1/a$ uma constante que representa a divisão média. Suponha que cada nós chegue a $k$ elementos ao final de $i$ divisões, isto é, $k=n/a^i$. Isolando $a$ e aplicando logaritmo chegamos a $i=\log_a(n/k)=O(\lg(n/k))$

Na parte do quicksort do algoritmo proposto, a recursão pára no nível $i=\lg(n / k)$, o que faz o tempo de execução esperado ser $O(n\lg(n / k))$. No entanto, isso deixa $n / k$ subarrays não ordenados e não intersectantes de comprimento (máximo) $k$.

Devido à natureza do algoritmo insertion sort, ele primeiro ordenará completamente um desses subarrays antes de considerar o próximo. Assim, ele tem a mesma complexidade que ordenar cada um desses arrays, ou seja, $\frac{n}{k}O(k^2) = O(nk)$.

Na teoria, se ignorarmos os fatores constantes, precisamos resolver

$$
\begin{aligned}
            & n\lg n \ge nk + n\lg{n / k} \\\\
\Rightarrow & \lg n \ge k + \lg n - \lg k \\\\
\Rightarrow & \lg k \ge k.
\end{aligned}
$$

O que não é possível.

Se adicionarmos os fatores constantes, obtemos

$$
\begin{aligned}
            & c_qn\lg n \ge c_ink + c_qn\lg(n / k) \\\\
\Rightarrow & c_q\lg n \ge c_ik + c_q\lg n - c_q\lg k \\\\
\Rightarrow & \lg k \ge \frac{c_i}{c_q}k.
\end{aligned}
$$

O que indica que pode haver um bom candidato. Além disso, os termos de ordem inferior também devem ser levados em consideração.

Na prática, $k$ deve ser escolhido experimentalmente.

## 7.4-6 $\star$

> Considere modificar o procedimento $\text{PARTITION}$ escolhendo aleatoriamente três elementos do array $A$ e particionando em torno de sua mediana (o valor do meio dos três elementos). Aproxime a probabilidade de obter no máximo uma divisão $\alpha$-para-$(1 - \alpha)$, como uma função de $\alpha$ no intervalo $0 < \alpha < 1$.

Primeiro, para simplificar, vamos assumir que podemos escolher o mesmo elemento duas vezes. Vamos também assumir que $0 < \alpha \le 1 / 2$.

Para obter tal divisão, dois dos três elementos precisam estar nos menores $\alpha n$ elementos. A probabilidade de ter um é $\alpha n / n = \alpha$. A probabilidade de ter exatamente dois é $\alpha^2 - \alpha^3$. Existem três maneiras em que dois elementos podem estar nos menores $\alpha n$ e uma maneira em que todos os três podem estar nos menores $\alpha n$, então a probabilidade de obter tal mediana é $3\alpha^2 - 2\alpha^3$. Obteremos a mesma divisão se a mediana estiver nos maiores $\alpha n$. Como os dois eventos são mutuamente exclusivos, a probabilidade é

$$\Pr\\{\text{Divisão Aceitável}\\} = 6\alpha^2 - 4\alpha^3 = 2\alpha^2(3 - 2\alpha).$$