## 2.3-1

> Usando a Figura 2.4 como modelo, ilustre a operação do merge sort em um array inicialmente contendo a sequência $\langle 3, 41, 52, 26, 38, 57, 9, 49 \rangle$.

$$[3] \quad [41] \quad [52] \quad [26] \quad [38] \quad [57] \quad [9] \quad [49]$$

$$\downarrow$$

$$[3|41] \quad [26|52] \quad [38|57] \quad [9|49]$$

$$\downarrow$$

$$[3|26|41|52] \quad [9|38|49|57]$$

$$\downarrow$$

$$[3|9|26|38|41|49|52|57]$$

## 2.3-2

> O teste na linha 1 do procedimento MERGE-SORT lê "se p ≥ r" em vez de "se p == r". Se o MERGE-SORT for chamado com p > r, o subarray A[p : r] estará vazio. Argumente que, desde que a chamada inicial de MERGE-SORT(A, 1, n) tenha n ≥ 1, o teste "se p == r" é suficiente para garantir que nenhuma chamada recursiva tenha p > r.

O teste "se p ≥ r" na linha 1 do procedimento mergeSort é usado para verificar se o subarray A[p : r] tem zero ou um elemento. Se p > r, então o subarray está vazio e se p = r, então o subarray possui apenas um elemento. Em ambos os casos, o subarray já está ordenado e a função retorna sem fazer mais chamadas recursivas.

Se a chamada inicial para mergeSort for feita com n ≥ 1, então é garantido que nenhuma chamada recursiva terá p > r. Isso ocorre porque o valor de q é calculado como o piso de (p + r)/2, o que garante que q será sempre menor que r. Como as chamadas recursivas são feitas com p e q ou q + 1 e r, conclui-se que p sempre será menor ou igual a r.

Vamos provar que se $p < r$, então $q < r$. Como $p$ e $r$ são inteiros e $p < r$, podemos escrever $r = p + k$ para algum número inteiro positivo $k$. Substituindo isso na expressão para $q$, temos: $q = ⌊(p + r)/2⌋ = ⌊(p + p + k)/2⌋ = ⌊(2p + k)/2⌋ = p + ⌊k/2⌋ < p + k = r$.

Agora vamos provar que p ≤ q. Como $q = p + ⌊k/2⌋$, e no mínimo $k=1$, portanto $q=p$ para $k=1$, caso contrário, $q>p$ para $k>1$.

Portanto, desde que a chamada inicial para mergeSort tenha n ≥ 1, o teste "se p ≠ r" seria suficiente para garantir que nenhuma chamada recursiva tenha p > r. No entanto, usar "se p ≥ r" em vez de "se p ≠ r" também lida com o caso em que a chamada inicial para mergeSort for feita com n < 1.

## 2.3-3

> Apresente um invariante de laço para o while das linhas 12–18 do procedimento MERGE. Mostre como usá-lo, juntamente com os whiles das linhas 20–23 e 24–27, para provar que o procedimento MERGE está correto.

Um invariante de laço para o while das linhas 12–18 do procedimento MERGE é que, no início de cada iteração do laço, o subarray $A[p : k-1]$ contém ordenados os $k-p$ menores elementos de $L[0 : nL-1]$ e $R[0 : nR-1]$.

Podemos usar esse invariante de laço, juntamente com os whiles das linhas 20–23 e 24–27, para provar que o procedimento MERGE está correto da seguinte maneira:

**Inicialização:** Antes da primeira iteração do laço (quando $k = p$), o subarray $A[p : k-1]$ está vazio, então ele contém ordenados trivialmente os $k-p = 0$ menores elementos de $L[0 : nL-1]$ e $R[0 : nR-1]$.

**Manutenção:** Suponha que no início de alguma iteração do laço, $A[p : k-1]$ contém ordenados os $k-p$ menores elementos de $L[0 : nL-1]$ e $R[0 : nR-1]$. Existem dois casos a serem considerados, dependendo se $L[i] \le R[j]$ ou não.

Se $L[i] \le R[j]$, então $L[i]$ é o menor elemento não incluso (unmerged), então ele é incluído em $A[k]$, e tanto $i$ quanto $k$ são incrementados. Como $L[i]$ é menor ou igual a todos os elementos restantes em $L$ e $R$, segue que após esta iteração, $A[p : k-1]$ contém ordenados os $k-p$ menores elementos de $L[0 : nL-1]$ e $R[0 : nR-1]$.

Se $L[i] \gt R[j]$, então $R[j]$ é o menor elemento não incluso, então ele é incluído em $A[k]$, e tanto $j$ quanto $k$ são incrementados. Como $R[j]$ é menor ou igual a todos os elementos restantes em $L$ e $R$, segue que após esta iteração, $A[p : k-1]$ contém ordenados os $k-p$ menores elementos de $L[0 : nL-1]$ e $R[0 : nR-1]$.

Em ambos os casos, o invariante de laço é mantido.

**Terminação:** O laço termina quando $i = nL$ ou $j = nR$. Nesse ponto, todos os elementos de um dos arrays $L$ ou $R$ foram incluídos (merged) em $A[p : r]$, então apenas os elementos do outro array permanecem para serem incluídos. Os whiles das linhas 20-23 e 24-27 copiam esses elementos restantes em $A[p : r]$. Como esses elementos restantes são todos maiores ou iguais aos elementos já incluídos em $A[p : r]$, segue-se que no final do procedimento MERGE, $A[p : r]$ contém todos os $nL + nR$ elementos de $L[0 : nL-1]$ e $R[0 : nR-1]$, ordenados.

Isso completa a prova de que o procedimento MERGE está correto.

## 2.3-4

> Use a indução matemática para mostrar que quando $n ≥ 2$ é uma potência exata de 2, a solução da recorrência
>
> $$
> T(n) =
> \begin{cases}
>     2             & \text{se $n = 2$,} \\\\
>     2T(n / 2) + n & \text{se $n > 2$}
> \end{cases}
> $$
>
> é $T(n) = n \lg n$.

- Caso base

  Para $n = 2^1$, $T(n) = 2\lg 2 = 2$.

- Suponha que $n = 2^k$, $T(n) = n\lg n = 2^k \lg 2^k = 2^kk$.

  Para $n = 2^{k + 1}$,

  $$
  \begin{aligned}
  T(n) & = 2T(2^{k + 1} / 2) + 2^{k + 1} \\\\
       & = 2T(2^k) + 2^{k + 1} \\\\
       & = 2 \cdot 2^kk + 2^{k + 1} \\\\
       & = 2^{k + 1}(k + 1) \\\\
       & = 2^{k + 1} \lg 2^{k + 1} \\\\
       & = n\lg n.
  \end{aligned}
  $$

Por I.M., $T(n) = n\lg n$, quando $n$ é uma potência exata de 2.

## 2.3-5

> Você também pode pensar em insertion sort como um algoritmo recursivo. Para ordenar $A[1 : n]$, ordene recursivamente o subarray $A[1 : n - 1]$ e então insira $A[n]$ no subarray ordenado $A[1 : n - 1]$. Escreva o pseudocódigo para essa versão recursiva do insertion sort. Dê uma recorrência para seu pior caso de tempo de execução.

Leva $\Theta(n)$ de tempo no pior caso para inserir $A[n]$ no array ordenado $A[1..n - 1]$. Portanto, a recorrência é

$$
T(n) = \begin{cases}
    \Theta(1)            & \text{se $n = 1$,} \\\\
    T(n - 1) + \Theta(n) & \text{se $n > 1$}.
\end{cases}
$$

A solução da recorrência é $\Theta(n^2)$.

## 2.3-6

> Voltando ao problema de busca (veja o Exercício 2.1-4), percebe-se que se o subarray sendo pesquisado já estiver ordenado, o algoritmo de busca pode verificar o elemento do meio do subarray em relação a $x$ e eliminar metade do subarray na busca. O algoritmo de **_busca binária_** repete esse procedimento, dividindo pela metade o tamanho da porção restante do subarray a cada vez. Escreva o pseudocódigo, seja iterativo ou recursivo, para busca binária. Argumente que o tempo de execução no pior caso da busca binária é $\Theta(\lg n)$.

- Iterativo:

  ```cpp
  ITERATIVE-BINARY-SEARCH(A, v, low, high)
      while low ≤ high
          mid = floor((low + high) / 2)
          if v == A[mid]
              return mid
          else if v > A[mid]
              low = mid + 1
          else high = mid - 1
      return NIL
  ```

- Recursivo:

  ```cpp
  RECURSIVE-BINARY-SEARCH(A, v, low, high)
      if low > high
          return NIL
      mid = floor((low + high) / 2)
      if v == A[mid]
          return mid
      else if v > A[mid]
          return RECURSIVE-BINARY-SEARCH(A, v, mid + 1, high)
      else return RECURSIVE-BINARY-SEARCH(A, v, low, mid - 1)
  ```

Cada vez que fazemos a comparação de $v$ com o elemento do meio, o intervalo de busca continua com metade do tamanho. O que nos dá a seguinte recorrência:

$$
T(n) = \begin{cases}
    \Theta(1)            & \text{se $n = 1$,} \\\\
    T(n / 2) + \Theta(1) & \text{se $n > 1$}.
\end{cases}
$$

A solução da recorrência é $T(n) = T(n/2^1) + \Theta(1) = T(n/2^2) + 2\Theta(1) = T(n/2^3) + 3\Theta(1) = T(n/2^k) + k\Theta(1)$.

Podemos continuar expandindo a recorrência até alcançarmos o caso base, quando $n/2^k=1$, isto é, $k=\lg n$. Substituindo $k$ na recorrência expandida, temos:

$T(n)=T(1)+\Theta(1)\lg n$.

Como $T(1)$ e $\Theta(1)$ são constantes, segue que $T(n)=\Theta(\lg n)$.

## 2.3-7

> O while das linhas 5–7 do procedimento $\text{INSERTION-SORT}$ na Seção 2.1 usa uma busca linear para percorrer (de trás para frente) o subarray ordenado $A[1 : i - 1]$. E se o insertion sort usasse uma busca binária (veja o Exercício 2.3-6) em vez de uma busca linear? Isso melhoraria o tempo de execução no pior caso do insertion sort para $\Theta(n\lg n)$?

Cada vez que o laço **while** das linhas 5-7 do $\text{INSERTION-SORT}$ percorre de volta através do array ordenado $A[1..j - 1]$. O laço não apenas busca o local correto para $A[j]$, mas também move cada um dos elementos do array que é maior que $A[j]$ uma posição para a direita (linha 6). Essas movimentações levam $\Theta(j)$ de tempo, que ocorre quando todos os $j - 1$ elementos precedendo $A[j]$ são maiores que $A[j]$. O tempo de execução da busca binária para procurar é $\Theta(\lg j)$, que ainda é dominado pelo tempo de execução das movimentações dos elementos $\Theta(j)$.

Portanto, não podemos melhorar o tempo de execução no pior caso do insertion sort para $\Theta(n\lg n)$.

## 2.3-8

> Descreva um algoritmo que, dado um conjunto $S$ de $n$ inteiros e outro inteiro $x$, determina se $S$ contém dois elementos que somam exatamente $x$. Seu algoritmo deve ter tempo de execução $\Theta(n \lg n)$ no pior caso.

Primeiro, ordene $S$, que leva $\Theta(n\lg n)$ de tempo.
Então, para cada elemento $s_i$ em $S$, $i = 1, \dots, n$, procure $s_i' = x - s_i$ em $A[i + 1..n]$ com busca binária, o que leva tempo $\Theta(\lg n)$.

- Se $s_i'$ for encontrado, retorne sua posição;
- Caso contrário, continue para a próxima iteração.

O tempo do algoritmo é $\Theta(n\lg n) + n \cdot \Theta(\lg n) = \Theta(n\lg n)$.